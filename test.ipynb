{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read a txt file and convert it to a dataframe\n",
    "def read_txt(path):\n",
    "    df = pd.read_csv(path, sep='\\t', header=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = pd.read_csv('MovieSummaries/plot_summaries.txt',header=None, sep=\"\\t\")\n",
    "movies = pd.read_csv('MovieSummaries/movie.metadata.tsv',header=None, sep=\"\\t\")\n",
    "characters = pd.read_csv('MovieSummaries/character.metadata.tsv',header=None, sep=\"\\t\")\n",
    "names = pd.read_csv('MovieSummaries/name.clusters.txt',header=None, sep=\"\\t\")\n",
    "tvtropes = pd.read_csv('MovieSummaries/tvtropes.clusters.txt',header=None, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.columns = ['WikiID', 'Plot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Wikipedia movie ID\n",
    "2. Freebase movie ID\n",
    "3. Movie name\n",
    "4. Movie release date\n",
    "5. Movie box office revenue\n",
    "6. Movie runtime\n",
    "7. Movie languages (Freebase ID:name tuples)\n",
    "8. Movie countries (Freebase ID:name tuples)\n",
    "9. Movie genres (Freebase ID:name tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.columns = ['WikiID', 'FreebaseID', 'Name', 'ReleaseDate', 'Revenue', 'Runtime', 'Languages', 'Countries', 'Genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_with_date = movies[-movies[\"ReleaseDate\"].isna()].copy(deep=True)\n",
    "dates = movie_with_date[\"ReleaseDate\"]\n",
    "date_years = dates.astype(str).str.extract(r'(\\d{4})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_ids = np.where(movies[\"ReleaseDate\"].isna())[0]\n",
    "no_date_filter = movies[\"ReleaseDate\"].astype(str).str.extract('(\\d{4})').isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_date_filter = movies[\"ReleaseDate\"].astype(str).str.extract('(\\d{4})').isna()\n",
    "na_ids = np.where(movies[\"ReleaseDate\"].astype(str).str.extract('(\\d{4})').isna().values)[0]\n",
    "no_date_movies = movies.iloc[na_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462       7582987\n",
       "1043      4724834\n",
       "1047     34055313\n",
       "1888     25496318\n",
       "5007     33382022\n",
       "           ...   \n",
       "77890    34502262\n",
       "78775    27785844\n",
       "78816     4421925\n",
       "79278    33934476\n",
       "79413     9170459\n",
       "Name: WikiID, Length: 73, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_date_movies[\"Revenue\"].isna().value_counts()\n",
    "no_date_movies.iloc[np.where(no_date_movies[\"Revenue\"].isna()==False)][\"WikiID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WikiID</th>\n",
       "      <th>FreebaseID</th>\n",
       "      <th>Name</th>\n",
       "      <th>ReleaseDate</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Languages</th>\n",
       "      <th>Countries</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81736</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81737</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81738</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81739</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81740</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81741 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       WikiID FreebaseID Name ReleaseDate  Revenue  Runtime Languages  \\\n",
       "0         NaN        NaN  NaN         NaN      NaN      NaN       NaN   \n",
       "1         NaN        NaN  NaN         NaN      NaN      NaN       NaN   \n",
       "2         NaN        NaN  NaN         NaN      NaN      NaN       NaN   \n",
       "3         NaN        NaN  NaN         NaN      NaN      NaN       NaN   \n",
       "4         NaN        NaN  NaN         NaN      NaN      NaN       NaN   \n",
       "...       ...        ...  ...         ...      ...      ...       ...   \n",
       "81736     NaN        NaN  NaN         NaN      NaN      NaN       NaN   \n",
       "81737     NaN        NaN  NaN         NaN      NaN      NaN       NaN   \n",
       "81738     NaN        NaN  NaN         NaN      NaN      NaN       NaN   \n",
       "81739     NaN        NaN  NaN         NaN      NaN      NaN       NaN   \n",
       "81740     NaN        NaN  NaN         NaN      NaN      NaN       NaN   \n",
       "\n",
       "      Countries Genres  \n",
       "0           NaN    NaN  \n",
       "1           NaN    NaN  \n",
       "2           NaN    NaN  \n",
       "3           NaN    NaN  \n",
       "4           NaN    NaN  \n",
       "...         ...    ...  \n",
       "81736       NaN    NaN  \n",
       "81737       NaN    NaN  \n",
       "81738       NaN    NaN  \n",
       "81739       NaN    NaN  \n",
       "81740       NaN    NaN  \n",
       "\n",
       "[81741 rows x 9 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_without_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\antho\\Desktop\\EPFL\\ADA_project\\test.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ADA_project/test.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#movies['ReleaseDate'] = pd.to_datetime(movies['ReleaseDate'], errors='ignore')\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ADA_project/test.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m movies[\u001b[39m\"\u001b[39;49m\u001b[39mReleaseDate\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mastype(\u001b[39mstr\u001b[39;49m)\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mextract(\u001b[39m'\u001b[39;49m\u001b[39m(\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39md\u001b[39;49m\u001b[39m{4}\u001b[39;49;00m\u001b[39m)\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ADA_project/test.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m movies[\u001b[39m\"\u001b[39m\u001b[39mReleaseDate\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\generic.py:6324\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6317\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m   6318\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m   6319\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m   6320\u001b[0m     ]\n\u001b[0;32m   6322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6323\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6324\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   6325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6327\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    449\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m    452\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    453\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    454\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    455\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    456\u001b[0m     using_cow\u001b[39m=\u001b[39;49musing_copy_on_write(),\n\u001b[0;32m    457\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    355\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(result_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[1;32m--> 511\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    513\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    515\u001b[0m refs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    239\u001b[0m     dtype \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39mnumpy_dtype\n\u001b[0;32m    241\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    243\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    244\u001b[0m     \u001b[39m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:187\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    184\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     values \u001b[39m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    189\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    136\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mor\u001b[39;00m is_object_dtype(arr\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[0;32m    137\u001b[0m     \u001b[39m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39;49mastype(dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    140\u001b[0m \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "#movies['ReleaseDate'] = pd.to_datetime(movies['ReleaseDate'], errors='ignore')\n",
    "movies[\"ReleaseDate\"].astype(str).str.extract('(\\d{4})').astype(int)\n",
    "movies[\"ReleaseDate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Characters data:\n",
    "1. Wikipedia movie ID\n",
    "2. Freebase movie ID\n",
    "3. Movie release date\n",
    "4. Character name\n",
    "5. Actor date of birth\n",
    "6. Actor gender\n",
    "7. Actor height (in meters)\n",
    "8. Actor ethnicity (Freebase ID)\n",
    "9. Actor name\n",
    "10. Actor age at movie release\n",
    "11. Freebase character/actor map ID\n",
    "12. Freebase character ID\n",
    "13. Freebase actor ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters.columns = ['WikiID', 'FreebaseID', 'ReleaseDate', 'CharacterName', 'DateOfBirth', 'Gender', 'Height', 'Ethnicity', 'Name', 'AgeAtRealease', 'FreebaseCharacterActorMapID', 'FreebaseCharacterID', 'FreebaseActorID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Imbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imdb_scraper as imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_revenue': 654264015.0,\n",
       " 'budget': 140000000.0,\n",
       " 'gross_domestic': 305413918.0,\n",
       " 'opening_weekend': 46630690.0,\n",
       " 'rating_score': 8.1,\n",
       " 'number_of_ratings': 1200000.0,\n",
       " 'watched_rank': 365.0,\n",
       " 'producer': 'Gore Verbinski'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of how to use the scraper\n",
    "myscraper = imdb.ImdbScraper()\n",
    "myscraper.get_imdb_infos(\"Pirate of the Caribbean: The Curse of the Black Pearl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n           = movies.shape[0]\n",
    "n_computer  = 6\n",
    "size        = n//n_computer\n",
    "\n",
    "# create a uniform partition of indices from 0 to n-1 for n_computer computers\n",
    "indices         = [i for i in range(n)]\n",
    "partitions      = [indices[i*size:(i+1)*size] for i in range(n_computer)]\n",
    "partitions[-1]  = partitions[-1] + indices[n_computer*size:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of elements: 81741\n",
      "partition size: 13623\n",
      "\n",
      "partition 0: (0, 13622)\n",
      "partition 1: (13623, 27245)\n",
      "partition 2: (27246, 40868)\n",
      "partition 3: (40869, 54491)\n",
      "partition 4: (54492, 68114)\n",
      "partition 5: (68115, 81740)\n"
     ]
    }
   ],
   "source": [
    "# show first and last element of each partition\n",
    "partition_intervals = [(partitions[i][0], partitions[i][-1]) for i in range(n_computer)]\n",
    "print(f\"number of elements: {n}\")\n",
    "print(f\"partition size: {size}\\n\")\n",
    "for i in range(len(partition_intervals)):\n",
    "    print(f\"partition {i}: {partition_intervals[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Select your index here:\n",
    "    - Anthony   0 & 1\n",
    "    - Anton     2\n",
    "    - Aymeric   3\n",
    "    - Eric      4\n",
    "    - Yara      5\n",
    "\"\"\"\n",
    "index = 0\n",
    "\n",
    "index_range = partitions[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\antho\\Desktop\\EPFL\\ADA_project\\test.ipynb Cell 18\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ADA_project/test.ipynb#X20sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m row_df \u001b[39m=\u001b[39m row_df\u001b[39m.\u001b[39mfillna(\u001b[39m'\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ADA_project/test.ipynb#X20sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# append the row DataFrame to the CSV file\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ADA_project/test.ipynb#X20sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m row_df\u001b[39m.\u001b[39;49mto_csv(csv_file, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ma\u001b[39;49m\u001b[39m'\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ADA_project/test.ipynb#X20sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m#print(f\"{name}  : {movie_infos}\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ada\\lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3773\u001b[0m     path_or_buf,\n\u001b[0;32m   3774\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3775\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3776\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3778\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3779\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3780\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3781\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3782\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3783\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3784\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3785\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3786\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3787\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3788\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3789\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ada\\lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ada\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    241\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    243\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    244\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    245\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    246\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    247\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ada\\lib\\site-packages\\pandas\\io\\common.py:737\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[1;32m--> 737\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[0;32m    739\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[0;32m    740\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    741\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ada\\lib\\site-packages\\pandas\\io\\common.py:599\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    591\u001b[0m \u001b[39mCheck if parent directory of a file exists, raise OSError if it does not\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39m    Path to check parent directory of\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    598\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[1;32m--> 599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39;49mis_dir():\n\u001b[0;32m    600\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ada\\lib\\pathlib.py:1439\u001b[0m, in \u001b[0;36mPath.is_dir\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1435\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1436\u001b[0m \u001b[39mWhether this path is a directory.\u001b[39;00m\n\u001b[0;32m   1437\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1438\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1439\u001b[0m     \u001b[39mreturn\u001b[39;00m S_ISDIR(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstat()\u001b[39m.\u001b[39mst_mode)\n\u001b[0;32m   1440\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1441\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _ignore_error(e):\n",
      "File \u001b[1;32mc:\\Users\\antho\\miniconda3\\envs\\ada\\lib\\pathlib.py:1232\u001b[0m, in \u001b[0;36mPath.stat\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstat\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1228\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m \u001b[39m    Return the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[0;32m   1230\u001b[0m \u001b[39m    os.stat() does.\u001b[39;00m\n\u001b[0;32m   1231\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1232\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mstat(\u001b[39mself\u001b[39;49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#movie_names = [\"The Avengers\", \"The Godfather\", \"Vice\", \"The Dark Knight\", \"OuiOui\"]\n",
    "\n",
    "# Adding date to have more accurate search results\n",
    "dataset_names = (movies[\"Name\"] + \" \" + movies[\"ReleaseDate\"].astype(str)).values\n",
    "movie_years = movies[\"ReleaseDate\"].astype(str).values\n",
    "\n",
    "# create an empty DataFrame for the first row\n",
    "header = pd.DataFrame(columns=[\"WikiID\", \"Name\", \"Date\", \"global_revenue\", \"budget\", \"gross_domestic\", \"opening_weekend\", \"rating_score\", \"number_of_ratings\", \"watched_rank\", \"producer\"])\n",
    "\n",
    "csv_file = 'MovieSummaries/imdb_scraped_data_' + str(index) + '.csv'\n",
    "\n",
    "myscraper = imdb.ImdbScraper()\n",
    "\n",
    "# if the csv_file doesn't exist, make a header\n",
    "if not os.path.isfile(csv_file):\n",
    "    # write the DataFrame to a CSV file\n",
    "    header.to_csv(csv_file, index=False)\n",
    "\n",
    "for i in index_range:\n",
    "    name = dataset_names[i]\n",
    "    wikiID = movies[\"WikiID\"].values[i]\n",
    "\n",
    "    movie_infos = myscraper.get_imdb_infos(name)\n",
    "    row = [wikiID, movies[\"Name\"].values[i], movies[\"ReleaseDate\"].values[i], *list(movie_infos.values())]\n",
    "\n",
    "    # create a new DataFrame for the row\n",
    "    row_df = pd.DataFrame([row], columns=header.columns)\n",
    "\n",
    "    # replace None values with the string 'None'\n",
    "    row_df = row_df.fillna('None')\n",
    "\n",
    "    # append the row DataFrame to the CSV file\n",
    "    row_df.to_csv(csv_file, mode='a', header=False, index=False)\n",
    "\n",
    "    #print(f\"{name}  : {movie_infos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TMBD API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmdb_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tmdb_id': 11,\n",
       " 'movie_name': 'Star Wars : Episode IV - A New Hope',\n",
       " 'release_date': '1977-05-25',\n",
       " 'revenue': 775398007,\n",
       " 'budget': 11000000,\n",
       " 'rating': 8.204,\n",
       " 'vote_count': 19278,\n",
       " 'popularity': 86.431,\n",
       " 'runtime': 121,\n",
       " 'production': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "my_tmdb_scraper = tmdb_scraper.tmdb_scraper()\n",
    "my_tmdb_scraper.get_tmdb_infos(\"Star Wars : Episode IV - A New Hope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names   = movies[\"Name\"].values\n",
    "\n",
    "# create an empty DataFrame for the first row\n",
    "header = pd.DataFrame(columns=[\"tmdb_id\", \"movie_name\", \"release_date\", \"revenue\", \"budget\", \"rating\", \"vote_count\", \"popularity\", \"runtime\", \"production\"])\n",
    "\n",
    "csv_file = 'MovieSummaries/tmbd_scraped_data.csv'\n",
    "\n",
    "# if the csv_file doesn't exist yet, make a header\n",
    "if not os.path.isfile(csv_file):\n",
    "    # write the DataFrame to a CSV file\n",
    "    header.to_csv(csv_file, index=False)\n",
    "\n",
    "index_range = np.arange(0, 10)\n",
    "\n",
    "for i in index_range:\n",
    "    name = dataset_names[i]\n",
    "\n",
    "    movie_infos = my_tmdb_scraper.get_tmdb_infos(name)\n",
    "    row = [*list(movie_infos.values())]\n",
    "\n",
    "    # create a new DataFrame for the row\n",
    "    row_df = pd.DataFrame([row], columns=header.columns)\n",
    "\n",
    "    # replace None values with the string 'None'\n",
    "    row_df = row_df.fillna('None')\n",
    "\n",
    "    # append the row DataFrame to the CSV file\n",
    "    row_df.to_csv(csv_file, mode='a', header=False, index=False)\n",
    "\n",
    "    #print(f\"{name}  : {movie_infos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(\"https://en.wikipedia.org/w/api.php?action=query&pageids=975900&format=json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batchcomplete': '',\n",
       " 'query': {'pages': {'975900': {'pageid': 975900,\n",
       "    'ns': 0,\n",
       "    'title': 'Ghosts of Mars'}}}}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tmdbsimple as tmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name = \"My Friend Ganesha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\antho\\Desktop\\EPFL\\ADA_Milestone_2\\test.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ADA_Milestone_2/test.ipynb#X50sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m popularity  \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39m\u001b[39mpopularity\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ADA_Milestone_2/test.ipynb#X50sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m runtime     \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39m\u001b[39mruntime\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ADA_Milestone_2/test.ipynb#X50sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m production  \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39;49m\u001b[39mproduction_companies\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antho/Desktop/EPFL/ADA_Milestone_2/test.ipynb#X50sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m release_date \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39m\u001b[39mrelease_date\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tmdb.REQUESTS_SESSION = requests.Session()\n",
    "search      = tmdb.Search()\n",
    "\n",
    "search.movie(query=movie_name)\n",
    "tmdb_id     = search.results[0]['id']\n",
    "result      = tmdb.Movies(tmdb_id).info()\n",
    "\n",
    "revenue     = result['revenue']\n",
    "budget      = result['budget']\n",
    "rating      = result['vote_average']\n",
    "vote_count  = result['vote_count']\n",
    "popularity  = result['popularity']\n",
    "runtime     = result['runtime']\n",
    "production  = result['production_companies'][0]['name']\n",
    "release_date = result['release_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ghosts of Mars 2001-08-24'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_name = dataset_names[0]\n",
    "movie_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# access the webpage\n",
    "driver.get(\"https://www.imdb.com/\")\n",
    "\n",
    "# find the search bar & search button\n",
    "search_bar = driver.find_element(\"xpath\", '//*[@id=\"suggestion-search\"]')\n",
    "search_button = driver.find_element(\"xpath\", '//*[@id=\"suggestion-search-button\"]')\n",
    "\n",
    "# search for the movie\n",
    "search_bar.send_keys(movie_name)\n",
    "search_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = soup.find_all(\"span\", {\"class\": \"ipc-metadata-list-summary-item__li\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span aria-disabled=\"false\" class=\"ipc-metadata-list-summary-item__li\">2001</span>,\n",
       " <span aria-disabled=\"false\" class=\"ipc-metadata-list-summary-item__li\">Natasha Henstridge, Ice Cube</span>,\n",
       " <span aria-disabled=\"false\" class=\"ipc-metadata-list-summary-item__li\">2001</span>,\n",
       " <span aria-disabled=\"false\" class=\"ipc-metadata-list-summary-item__li\">Vidéo</span>,\n",
       " <span aria-disabled=\"false\" class=\"ipc-metadata-list-summary-item__li\">John Carpenter</span>,\n",
       " <span aria-disabled=\"false\" class=\"ipc-metadata-list-summary-item__li\">2001</span>,\n",
       " <span aria-disabled=\"false\" class=\"ipc-metadata-list-summary-item__li\">Vidéo</span>,\n",
       " <span aria-disabled=\"false\" class=\"ipc-metadata-list-summary-item__li\">Anthrax, Tiago Becker</span>,\n",
       " <span aria-disabled=\"false\" class=\"ipc-metadata-list-summary-item__li\">2001</span>,\n",
       " <span aria-disabled=\"false\" class=\"ipc-metadata-list-summary-item__li\">Vidéo</span>,\n",
       " <span aria-disabled=\"false\" class=\"ipc-metadata-list-summary-item__li\">Danielle Burgio, John Carpenter</span>,\n",
       " <span aria-disabled=\"false\" class=\"ipc-metadata-list-summary-item__li\">2020</span>,\n",
       " <span aria-disabled=\"false\" class=\"ipc-metadata-list-summary-item__li\">S1.E23</span>,\n",
       " <span aria-disabled=\"false\" class=\"ipc-metadata-list-summary-item__li\">Épisode de podcast</span>,\n",
       " <span aria-disabled=\"false\" class=\"ipc-metadata-list-summary-item__li\">Série de podcast</span>]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WikiID                                                    175026\n",
       "FreebaseID                                             /m/017n1p\n",
       "Name                                               Sarah and Son\n",
       "ReleaseDate                                                 1930\n",
       "Revenue                                                      NaN\n",
       "Runtime                                                     86.0\n",
       "Languages                     {\"/m/02h40lc\": \"English Language\"}\n",
       "Countries              {\"/m/09c7w0\": \"United States of America\"}\n",
       "Genres         {\"/m/07s9rl0\": \"Drama\", \"/m/01g6gs\": \"Black-an...\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find the first result\n",
    "first_result = driver.find_element(\"xpath\", '//*[@id=\"__next\"]/main/div[2]/div[3]/section/div/div[1]/section[2]/div[2]/ul/li[1]')\n",
    "first_result.click()\n",
    "\n",
    "#parse the resulting webpage\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "box_office = soup.find('div', {'data-testid': \"title-boxoffice-section\"})\n",
    "try:\n",
    "    brut_li                 = box_office.find('li', {'data-testid' : \"title-boxoffice-cumulativeworldwidegross\"})\n",
    "    global_revenue_raw      = brut_li.find('span', {'class' : \"ipc-metadata-list-item__list-content-item\"}).text\n",
    "    global_revenue          = int(re.findall(r'\\d+', global_revenue_raw.replace('\\u202f', ''))[0])\n",
    "except:\n",
    "    global_revenue          = None\n",
    "\n",
    "try:\n",
    "    budget_li               = box_office.find('li', {'data-testid' : \"title-boxoffice-budget\"})\n",
    "    budget_raw              = budget_li.find('span', {'class' : \"ipc-metadata-list-item__list-content-item\"}).text\n",
    "    budget                  = int(re.findall(r'\\d+', budget_raw.replace('\\u202f', ''))[0])\n",
    "except:\n",
    "    budget = None\n",
    "\n",
    "try:\n",
    "    gross_domestic_li       = box_office.find('li', {'data-testid' : \"title-boxoffice-grossdomestic\"})\n",
    "    gross_domestic_raw      = gross_domestic_li.find('span', {'class' : \"ipc-metadata-list-item__list-content-item\"}).text\n",
    "    gross_domestic          = int(re.findall(r'\\d+', gross_domestic_raw.replace('\\u202f', ''))[0])\n",
    "except:\n",
    "    gross_domestic          = None\n",
    "\n",
    "try:\n",
    "    opening_weekend_li      = box_office.find('li', {'data-testid' : \"title-boxoffice-openingweekenddomestic\"})\n",
    "    opening_weekend_raw     = opening_weekend_li.find('span', {'class' : \"ipc-metadata-list-item__list-content-item\"}).text\n",
    "    opening_weekend         = int(re.findall(r'\\d+', opening_weekend_raw.replace('\\u202f', ''))[0])\n",
    "except:\n",
    "    opening_weekend         = None\n",
    "\n",
    "try:\n",
    "    rating_score_div        = soup.find('div', {'data-testid' : \"hero-rating-bar__aggregate-rating__score\"})\n",
    "    rating_score_raw        = rating_score_div.text\n",
    "    rating_score            = float(re.findall(r'\\d{1}.\\d{1}', rating_score_raw.replace(',', '.').replace('\\u202f', ''))[0])\n",
    "except:\n",
    "    rating_score            = None\n",
    "\n",
    "try:\n",
    "    number_of_ratings_div   = soup.find('div', {'data-testid' : \"hero-rating-bar__aggregate-rating\"})\n",
    "    number_of_ratings_raw   = number_of_ratings_div.find('div', {'class' : \"sc-bde20123-3 bjjENQ\"}).text\n",
    "    number_of_ratings       = float(re.findall(r'\\d+.?\\d?', number_of_ratings_raw.replace(',', '.').replace('\\u202f', ''))[0])\n",
    "\n",
    "    rating_unit             = number_of_ratings_raw[-1]\n",
    "    if (rating_unit=='M'):\n",
    "        number_of_ratings   = 1000000*number_of_ratings\n",
    "    elif (rating_unit=='k'):\n",
    "        number_of_ratings   = 1000*number_of_ratings\n",
    "except:\n",
    "    number_of_ratings       = None\n",
    "\n",
    "try:\n",
    "    watched_rank_div        = soup.find('div', {'data-testid' : \"hero-rating-bar__popularity\"})\n",
    "    watched_rank_raw        = watched_rank_div.find('div', {'data-testid' : \"hero-rating-bar__popularity__score\"}).text\n",
    "    watched_rank            = int(re.findall(r'\\d+', watched_rank_raw.replace('\\u202f', ''))[0])\n",
    "except:\n",
    "    watched_rank            = None\n",
    "\n",
    "try:\n",
    "    cast_section            = soup.find('section', {\"data-testid\" : \"title-cast\"})\n",
    "    cast_ul                 = cast_section.find('ul', {\"class\" : \"ipc-metadata-list ipc-metadata-list--dividers-all sc-bfec09a1-8 iiDmgX ipc-metadata-list--base\"})\n",
    "    cast_raw                = cast_ul.find('a', {'class' : 'ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link'}).text\n",
    "    producer               = cast_raw\n",
    "except:\n",
    "    producer                = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
